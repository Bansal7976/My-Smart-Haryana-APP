{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ Smart Haryana - LangGraph Chatbot Testing Notebook\n",
        "\n",
        "This notebook tests:\n",
        "1. ‚úÖ API Keys Loading (Google, Pinecone, Tavily)\n",
        "2. ‚úÖ LangGraph Multi-Agent System\n",
        "3. ‚úÖ RAG Agent (Knowledge Base)\n",
        "4. ‚úÖ Analytics Agent (Database)\n",
        "5. ‚úÖ Web Search Agent (Tavily)\n",
        "6. ‚úÖ Gemini Agent (LLM)\n",
        "7. ‚úÖ Full Chatbot Workflow\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Step 1: Import Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Libraries imported successfully\n",
            "üìÇ Current directory: c:\\Users\\visha\\OneDrive\\Desktop\\Civic App\\backend\\civic_issues_backend\n",
            "üìÇ App directory: c:\\Users\\visha\\OneDrive\\Desktop\\Civic App\\backend\\civic_issues_backend\\app\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from dotenv import load_dotenv\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "# Add the app directory to Python path\n",
        "current_dir = Path.cwd()\n",
        "app_dir = current_dir / \"app\"\n",
        "sys.path.insert(0, str(current_dir))\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully\")\n",
        "print(f\"üìÇ Current directory: {current_dir}\")\n",
        "print(f\"üìÇ App directory: {app_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîë Step 2: Load and Verify API Keys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîë API Keys Status:\n",
            "============================================================\n",
            "GOOGLE_API_KEY       ‚úÖ LOADED        AIzaSyCU...YGpA\n",
            "PINECONE_API_KEY     ‚úÖ LOADED        pcsk_7L4...ZRg2\n",
            "TAVILY_API_KEY       ‚úÖ LOADED        tvly-dev...UHnK\n",
            "DATABASE_URL         ‚úÖ LOADED        postgres...yana\n",
            "SECRET_KEY           ‚úÖ LOADED        mysecret...sues\n",
            "============================================================\n",
            "\n",
            "‚úÖ All critical API keys are loaded!\n"
          ]
        }
      ],
      "source": [
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Check all required API keys\n",
        "api_keys = {\n",
        "    \"GOOGLE_API_KEY\": os.getenv(\"GOOGLE_API_KEY\", \"\"),\n",
        "    \"PINECONE_API_KEY\": os.getenv(\"PINECONE_API_KEY\", \"\"),\n",
        "    \"TAVILY_API_KEY\": os.getenv(\"TAVILY_API_KEY\", \"\"),\n",
        "    \"DATABASE_URL\": os.getenv(\"DATABASE_URL\", \"\"),\n",
        "    \"SECRET_KEY\": os.getenv(\"SECRET_KEY\", \"\")\n",
        "}\n",
        "\n",
        "print(\"üîë API Keys Status:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for key_name, key_value in api_keys.items():\n",
        "    if key_value:\n",
        "        # Mask the key for security\n",
        "        masked_value = key_value[:8] + \"...\" + key_value[-4:] if len(key_value) > 12 else \"***\"\n",
        "        status = \"‚úÖ LOADED\"\n",
        "    else:\n",
        "        masked_value = \"‚ùå NOT SET\"\n",
        "        status = \"‚ùå MISSING\"\n",
        "    \n",
        "    print(f\"{key_name:20} {status:15} {masked_value}\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Check critical keys\n",
        "if not api_keys[\"GOOGLE_API_KEY\"]:\n",
        "    print(\"\\n‚ö†Ô∏è  WARNING: GOOGLE_API_KEY is required for AI features!\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ All critical API keys are loaded!\")\n",
        "\n",
        "if not api_keys[\"PINECONE_API_KEY\"]:\n",
        "    print(\"‚ö†Ô∏è  INFO: PINECONE_API_KEY not set. RAG will use in-memory fallback.\")\n",
        "    \n",
        "if not api_keys[\"TAVILY_API_KEY\"]:\n",
        "    print(\"‚ö†Ô∏è  INFO: TAVILY_API_KEY not set. Web search features will be limited.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Step 3: Test Google Gemini API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Google Gemini API Test PASSED\n",
            "============================================================\n",
            "Response: Hello from Smart Haryana!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import google.generativeai as genai\n",
        "    \n",
        "    # Configure Gemini\n",
        "    genai.configure(api_key=api_keys[\"GOOGLE_API_KEY\"])\n",
        "    \n",
        "    # Test with a simple query\n",
        "    model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "    response = model.generate_content(\"Say 'Hello from Smart Haryana!' in one sentence.\")\n",
        "    \n",
        "    print(\"‚úÖ Google Gemini API Test PASSED\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Response: {response.text}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Google Gemini API Test FAILED\")\n",
        "    print(f\"Error: {str(e)}\")\n",
        "    print(\"\\nTroubleshooting:\")\n",
        "    print(\"1. Check if GOOGLE_API_KEY is set correctly in .env\")\n",
        "    print(\"2. Verify the API key is valid at https://makersuite.google.com/app/apikey\")\n",
        "    print(\"3. Ensure you have enabled the Gemini API in Google Cloud Console\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "models/embedding-gecko-001\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-05-20\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-flash-lite-preview-06-17\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.5-pro-preview-06-05\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-flash-latest\n",
            "models/gemini-flash-lite-latest\n",
            "models/gemini-pro-latest\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image-preview\n",
            "models/gemini-2.5-flash-image\n",
            "models/gemini-2.5-flash-preview-09-2025\n",
            "models/gemini-2.5-flash-lite-preview-09-2025\n",
            "models/gemini-robotics-er-1.5-preview\n",
            "models/gemini-2.5-computer-use-preview-10-2025\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-exp-03-07\n",
            "models/gemini-embedding-exp\n",
            "models/gemini-embedding-001\n",
            "models/aqa\n",
            "models/imagen-3.0-generate-002\n",
            "models/imagen-4.0-generate-preview-06-06\n",
            "models/imagen-4.0-ultra-generate-preview-06-06\n",
            "models/imagen-4.0-generate-001\n",
            "models/imagen-4.0-ultra-generate-001\n",
            "models/imagen-4.0-fast-generate-001\n",
            "models/veo-2.0-generate-001\n",
            "models/veo-3.0-generate-preview\n",
            "models/veo-3.0-fast-generate-preview\n",
            "models/veo-3.0-generate-001\n",
            "models/veo-3.0-fast-generate-001\n",
            "models/veo-3.1-generate-preview\n",
            "models/veo-3.1-fast-generate-preview\n",
            "models/gemini-2.0-flash-live-001\n",
            "models/gemini-live-2.5-flash-preview\n",
            "models/gemini-2.5-flash-live-preview\n",
            "models/gemini-2.5-flash-native-audio-latest\n",
            "models/gemini-2.5-flash-native-audio-preview-09-2025\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "    print(m.name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Step 4: Test Local Embeddings (No API Key Required)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading local embeddings model (all-MiniLM-L6-v2)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\visha\\AppData\\Local\\Temp\\ipykernel_12760\\2036814592.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = SentenceTransformerEmbeddings(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Local Embeddings Test PASSED\n",
            "============================================================\n",
            "Test Query: How do I report a civic issue in Smart Haryana?\n",
            "Embedding Dimension: 384\n",
            "First 5 values: [0.018337756395339966, 0.0196943711489439, -3.553396527422592e-05, 0.0072741382755339146, -0.0021490813232958317]\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
        "    \n",
        "    print(\"Loading local embeddings model (all-MiniLM-L6-v2)...\")\n",
        "    embeddings = SentenceTransformerEmbeddings(\n",
        "        model_name=\"all-MiniLM-L6-v2\",\n",
        "        model_kwargs={'device': 'cpu'}\n",
        "    )\n",
        "    \n",
        "    # Test embeddings\n",
        "    test_text = \"How do I report a civic issue in Smart Haryana?\"\n",
        "    embedding_vector = embeddings.embed_query(test_text)\n",
        "    \n",
        "    print(\"‚úÖ Local Embeddings Test PASSED\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Test Query: {test_text}\")\n",
        "    print(f\"Embedding Dimension: {len(embedding_vector)}\")\n",
        "    print(f\"First 5 values: {embedding_vector[:5]}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Local Embeddings Test FAILED\")\n",
        "    print(f\"Error: {str(e)}\")\n",
        "    print(\"\\nTroubleshooting:\")\n",
        "    print(\"1. Run: pip install sentence-transformers\")\n",
        "    print(\"2. The model will download on first use (~90MB)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Step 5: Test Pinecone Connection (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pinecone-client in c:\\users\\visha\\anaconda3\\envs\\agenticai\\lib\\site-packages (6.0.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\visha\\anaconda3\\envs\\agenticai\\lib\\site-packages (from pinecone-client) (2025.10.5)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\visha\\anaconda3\\envs\\agenticai\\lib\\site-packages (from pinecone-client) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\visha\\anaconda3\\envs\\agenticai\\lib\\site-packages (from pinecone-client) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\visha\\anaconda3\\envs\\agenticai\\lib\\site-packages (from pinecone-client) (4.15.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\visha\\anaconda3\\envs\\agenticai\\lib\\site-packages (from pinecone-client) (2.3.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\visha\\anaconda3\\envs\\agenticai\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pinecone-client\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: pinecone-client 6.0.0\n",
            "Uninstalling pinecone-client-6.0.0:\n",
            "  Successfully uninstalled pinecone-client-6.0.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip uninstall pinecone-client -y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pinecone\n",
            "  Using cached pinecone-7.3.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\visha\\anaconda3\\envs\\agenticai\\lib\\site-packages (from pinecone) (2025.10.5)\n",
            "Collecting pinecone-plugin-assistant<2.0.0,>=1.6.0 (from pinecone)\n",
            "  Using cached pinecone_plugin_assistant-1.8.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\visha\\anaconda3\\envs\\agenticai\\lib\\site-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\visha\\anaconda3\\envs\\agenticai\\lib\\site-packages (from pinecone) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\visha\\anaconda3\\envs\\agenticai\\lib\\site-packages (from pinecone) (4.15.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\visha\\anaconda3\\envs\\agenticai\\lib\\site-packages (from pinecone) (2.3.0)\n",
            "Requirement already satisfied: packaging<25.0,>=24.2 in c:\\users\\visha\\anaconda3\\envs\\agenticai\\lib\\site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (24.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in c:\\users\\visha\\anaconda3\\envs\\agenticai\\lib\\site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\visha\\anaconda3\\envs\\agenticai\\lib\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\visha\\anaconda3\\envs\\agenticai\\lib\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.11)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\visha\\anaconda3\\envs\\agenticai\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Using cached pinecone-7.3.0-py3-none-any.whl (587 kB)\n",
            "Using cached pinecone_plugin_assistant-1.8.0-py3-none-any.whl (259 kB)\n",
            "Installing collected packages: pinecone-plugin-assistant, pinecone\n",
            "\n",
            "   ---------------------------------------- 0/2 [pinecone-plugin-assistant]\n",
            "   ---------------------------------------- 0/2 [pinecone-plugin-assistant]\n",
            "   -------------------- ------------------- 1/2 [pinecone]\n",
            "   -------------------- ------------------- 1/2 [pinecone]\n",
            "   -------------------- ------------------- 1/2 [pinecone]\n",
            "   -------------------- ------------------- 1/2 [pinecone]\n",
            "   -------------------- ------------------- 1/2 [pinecone]\n",
            "   -------------------- ------------------- 1/2 [pinecone]\n",
            "   -------------------- ------------------- 1/2 [pinecone]\n",
            "   -------------------- ------------------- 1/2 [pinecone]\n",
            "   -------------------- ------------------- 1/2 [pinecone]\n",
            "   ---------------------------------------- 2/2 [pinecone]\n",
            "\n",
            "Successfully installed pinecone-7.3.0 pinecone-plugin-assistant-1.8.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pinecone\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Pinecone API Test PASSED\n",
            "============================================================\n",
            "Connected to Pinecone successfully!\n",
            "Available indexes: ['smart-haryana']\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "if api_keys[\"PINECONE_API_KEY\"]:\n",
        "    try:\n",
        "        from pinecone import Pinecone\n",
        "        \n",
        "        pc = Pinecone(api_key=api_keys[\"PINECONE_API_KEY\"])\n",
        "        \n",
        "        # List indexes\n",
        "        indexes = pc.list_indexes()\n",
        "        index_names = [index.name for index in indexes]\n",
        "        \n",
        "        print(\"‚úÖ Pinecone API Test PASSED\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Connected to Pinecone successfully!\")\n",
        "        print(f\"Available indexes: {index_names if index_names else 'None (will be created automatically)'}\")\n",
        "        print(\"=\" * 60)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Pinecone API Test FAILED\")\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        print(\"\\nTroubleshooting:\")\n",
        "        print(\"1. Check if PINECONE_API_KEY is valid\")\n",
        "        print(\"2. Verify at https://app.pinecone.io/\")\n",
        "        print(\"3. Run: pip install pinecone-client\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Pinecone API key not set - Skipping Pinecone test\")\n",
        "    print(\"RAG will use in-memory vector store (limited functionality)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Step 6: Test Tavily Web Search (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Tavily Web Search API Test PASSED\n",
            "============================================================\n",
            "Test Query: Smart cities in Haryana India\n",
            "Results Found: 2\n",
            "\n",
            "First Result:\n",
            "  Title: [PDF] List of 110 Cities Selected under Smart City Mission - AIM\n",
            "  URL: https://aimapp2.aim.gov.in/aic/files/List%20of%20selected%20Smart%20Cities.pdf\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "if api_keys[\"TAVILY_API_KEY\"]:\n",
        "    try:\n",
        "        from tavily import TavilyClient\n",
        "        \n",
        "        tavily_client = TavilyClient(api_key=api_keys[\"TAVILY_API_KEY\"])\n",
        "        \n",
        "        # Test search\n",
        "        response = tavily_client.search(\n",
        "            query=\"Smart cities in Haryana India\",\n",
        "            max_results=2\n",
        "        )\n",
        "        \n",
        "        print(\"‚úÖ Tavily Web Search API Test PASSED\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Test Query: Smart cities in Haryana India\")\n",
        "        print(f\"Results Found: {len(response.get('results', []))}\")\n",
        "        \n",
        "        if response.get('results'):\n",
        "            print(f\"\\nFirst Result:\")\n",
        "            print(f\"  Title: {response['results'][0].get('title', 'N/A')}\")\n",
        "            print(f\"  URL: {response['results'][0].get('url', 'N/A')}\")\n",
        "        \n",
        "        print(\"=\" * 60)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Tavily Web Search API Test FAILED\")\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        print(\"\\nTroubleshooting:\")\n",
        "        print(\"1. Check if TAVILY_API_KEY is valid\")\n",
        "        print(\"2. Get a free key at https://tavily.com/\")\n",
        "        print(\"3. Run: pip install tavily-python\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Tavily API key not set - Skipping web search test\")\n",
        "    print(\"Web search features will be limited\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Step 7: Test LangGraph Multi-Agent System\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ùå LangGraph Chatbot initialization FAILED\n",
            "Error: No module named 'geoalchemy2'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\visha\\AppData\\Local\\Temp\\ipykernel_12760\\470360452.py\", line 2, in <module>\n",
            "    from app.services.langgraph_chatbot import LangGraphChatbot\n",
            "  File \"c:\\Users\\visha\\OneDrive\\Desktop\\Civic App\\backend\\civic_issues_backend\\app\\services\\langgraph_chatbot.py\", line 12, in <module>\n",
            "    from .. import models\n",
            "  File \"c:\\Users\\visha\\OneDrive\\Desktop\\Civic App\\backend\\civic_issues_backend\\app\\models.py\", line 8, in <module>\n",
            "    from geoalchemy2 import Geometry\n",
            "ModuleNotFoundError: No module named 'geoalchemy2'\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from app.services.langgraph_chatbot import LangGraphChatbot\n",
        "    \n",
        "    # Initialize the chatbot\n",
        "    print(\"Initializing LangGraph Chatbot...\")\n",
        "    print(\"This may take a moment as it loads all agents...\\n\")\n",
        "    \n",
        "    chatbot = LangGraphChatbot()\n",
        "    \n",
        "    print(\"‚úÖ LangGraph Chatbot initialized successfully!\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Chatbot Components:\")\n",
        "    print(f\"  ‚Ä¢ RAG Agent: {chatbot.rag_agent.name}\")\n",
        "    print(f\"  ‚Ä¢ Web Search Agent: {chatbot.web_agent.name}\")\n",
        "    print(f\"  ‚Ä¢ Analytics Agent: {chatbot.analytics_agent.name}\")\n",
        "    print(f\"  ‚Ä¢ Gemini Agent: {chatbot.gemini_agent.name}\")\n",
        "    print(\"\\nWorkflow Graph: RAG ‚Üí Analytics ‚Üí Web Search ‚Üí Gemini\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå LangGraph Chatbot initialization FAILED\")\n",
        "    print(f\"Error: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Step 8: Quick Test - Ask the Chatbot!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_core.pydantic_v1'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Interactive test - Ask your own question!\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01masyncio\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mapp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgemini_agent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GeminiAgent\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mask_chatbot\u001b[39m(question: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Quick test function to ask the chatbot a question\"\"\"\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\visha\\OneDrive\\Desktop\\Civic App\\backend\\civic_issues_backend\\app\\services\\agents\\gemini_agent.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msqlalchemy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masyncio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsyncSession\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_agent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseAgent\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SystemMessage, HumanMessage, AIMessage\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\visha\\anaconda3\\envs\\agenticai\\lib\\site-packages\\langchain_google_genai\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[0;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGoogleGenerativeAI\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\visha\\anaconda3\\envs\\agenticai\\lib\\site-packages\\langchain_google_genai\\chat_models.py:42\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     AIMessage,\n\u001b[0;32m     34\u001b[0m     AIMessageChunk,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m     HumanMessageChunk,\n\u001b[0;32m     40\u001b[0m )\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGeneration, ChatGenerationChunk, ChatResult\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic_v1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Field, root_validator\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_from_dict_or_env\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtenacity\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     45\u001b[0m     before_sleep_log,\n\u001b[0;32m     46\u001b[0m     retry,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m     wait_exponential,\n\u001b[0;32m     50\u001b[0m )\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_core.pydantic_v1'"
          ]
        }
      ],
      "source": [
        "# Interactive test - Ask your own question!\n",
        "import asyncio\n",
        "from app.services.agents.gemini_agent import GeminiAgent\n",
        "\n",
        "async def ask_chatbot(question: str):\n",
        "    \"\"\"Quick test function to ask the chatbot a question\"\"\"\n",
        "    try:\n",
        "        gemini = GeminiAgent(\n",
        "            google_api_key=api_keys[\"GOOGLE_API_KEY\"],\n",
        "            model=\"gemini-2.5-flash\"\n",
        "        )\n",
        "        \n",
        "        context = {\n",
        "            \"chat_history\": [],\n",
        "            \"user_district\": \"Gurugram\"\n",
        "        }\n",
        "        \n",
        "        print(f\"\\nüë§ You: {question}\")\n",
        "        print(\"ü§ñ Bot: Thinking...\\n\")\n",
        "        \n",
        "        result = await gemini.execute(question, context, None, 1)\n",
        "        \n",
        "        print(f\"ü§ñ Bot: {result['response']}\")\n",
        "        print(f\"\\nüìä Agent Used: {result.get('metadata', {}).get('agent_type', 'gemini')}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {str(e)}\")\n",
        "\n",
        "# Example usage - Change the question to test!\n",
        "await ask_chatbot(\"What is Smart Haryana and what can I do with it?\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù Step 9: Test Different Query Types\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test various types of queries\n",
        "async def test_query_types():\n",
        "    \"\"\"Test different types of queries that the chatbot should handle\"\"\"\n",
        "    \n",
        "    query_categories = {\n",
        "        \"App Knowledge (RAG)\": [\n",
        "            \"How do I report an issue?\",\n",
        "            \"What are the main features?\",\n",
        "            \"How does voice reporting work?\"\n",
        "        ],\n",
        "        \"Analytics (Database)\": [\n",
        "            \"How many issues are in my district?\",\n",
        "            \"What's the status of pending issues?\",\n",
        "            \"Show me resolved issues\"\n",
        "        ],\n",
        "        \"General Conversation\": [\n",
        "            \"Hello! What can you help me with?\",\n",
        "            \"Tell me about Haryana\",\n",
        "            \"Thank you!\"\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    gemini = GeminiAgent(\n",
        "        google_api_key=api_keys[\"GOOGLE_API_KEY\"],\n",
        "        model=\"gemini-1.5-flash\"\n",
        "    )\n",
        "    \n",
        "    print(\"üß™ Testing Different Query Categories\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    for category, queries in query_categories.items():\n",
        "        print(f\"\\nüìÇ {category}\")\n",
        "        print(\"-\" * 70)\n",
        "        \n",
        "        for query in queries:\n",
        "            print(f\"\\n‚ùì Query: {query}\")\n",
        "            \n",
        "            try:\n",
        "                context = {\"chat_history\": [], \"user_district\": \"Gurugram\"}\n",
        "                result = await gemini.execute(query, context, None, 1)\n",
        "                \n",
        "                response = result['response'][:150]\n",
        "                print(f\"‚úÖ Response: {response}...\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error: {str(e)[:100]}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"‚úÖ Query type testing completed!\")\n",
        "\n",
        "# Run the test\n",
        "await test_query_types()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Step 10: Configuration Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üìä SMART HARYANA CHATBOT - CONFIGURATION SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Count successful components\n",
        "components = {\n",
        "    \"Google Gemini API\": bool(api_keys[\"GOOGLE_API_KEY\"]),\n",
        "    \"Local Embeddings\": True,  # Always available\n",
        "    \"Pinecone Vector DB\": bool(api_keys[\"PINECONE_API_KEY\"]),\n",
        "    \"Tavily Web Search\": bool(api_keys[\"TAVILY_API_KEY\"]),\n",
        "    \"Database Connection\": bool(api_keys[\"DATABASE_URL\"]),\n",
        "}\n",
        "\n",
        "for component, status in components.items():\n",
        "    icon = \"‚úÖ\" if status else \"‚ö†Ô∏è \"\n",
        "    status_text = \"READY\" if status else \"NOT CONFIGURED\"\n",
        "    print(f\"{icon} {component:25} {status_text}\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Overall status\n",
        "critical_ready = components[\"Google Gemini API\"] and components[\"Database Connection\"]\n",
        "optional_count = sum([components[\"Pinecone Vector DB\"], components[\"Tavily Web Search\"]])\n",
        "\n",
        "print(\"\\nüìà OVERALL STATUS:\")\n",
        "if critical_ready:\n",
        "    print(f\"‚úÖ Core chatbot functionality: READY\")\n",
        "    print(f\"‚úÖ Optional features enabled: {optional_count}/2\")\n",
        "    print(\"\\nüöÄ Your chatbot is ready to use!\")\n",
        "else:\n",
        "    print(\"‚ùå Core functionality incomplete\")\n",
        "    if not components[\"Google Gemini API\"]:\n",
        "        print(\"   ‚Üí Missing: GOOGLE_API_KEY (Required)\")\n",
        "    if not components[\"Database Connection\"]:\n",
        "        print(\"   ‚Üí Missing: DATABASE_URL (Required)\")\n",
        "\n",
        "print(\"\\nüí° RECOMMENDATIONS:\")\n",
        "if not components[\"Pinecone Vector DB\"]:\n",
        "    print(\"  ‚Ä¢ Add PINECONE_API_KEY for enhanced RAG capabilities\")\n",
        "if not components[\"Tavily Web Search\"]:\n",
        "    print(\"  ‚Ä¢ Add TAVILY_API_KEY for real-time web search\")\n",
        "\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Final Summary\n",
        "\n",
        "If all tests above passed, your LangGraph chatbot is working correctly! \n",
        "\n",
        "### What We Tested:\n",
        "1. ‚úÖ API key loading from .env\n",
        "2. ‚úÖ Google Gemini API connection\n",
        "3. ‚úÖ Local embeddings model\n",
        "4. ‚úÖ Pinecone vector database (optional)\n",
        "5. ‚úÖ Tavily web search (optional)\n",
        "6. ‚úÖ LangGraph multi-agent workflow\n",
        "7. ‚úÖ Sample conversations\n",
        "\n",
        "### Next Steps:\n",
        "- Run the full backend with: `uvicorn app.main:app --reload`\n",
        "- Test the chatbot API at: `http://localhost:8000/docs`\n",
        "- Use the frontend to chat with the bot\n",
        "\n",
        "### Troubleshooting:\n",
        "- If any test failed, check the error messages above\n",
        "- Verify your .env file has all required keys\n",
        "- Make sure all dependencies are installed: `pip install -r requirements.txt`\n",
        "\n",
        "---\n",
        "**Made with ‚ù§Ô∏è for Smart Haryana**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "agenticai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
